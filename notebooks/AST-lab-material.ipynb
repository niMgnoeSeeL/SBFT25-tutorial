{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use **Fuzzing Book** Resources\n",
    "\n",
    "Clone the [Fuzzing Book](https://www.fuzzingbook.org/) repository and put this notebook under the directory `fuzzingbook/notebooks/`. Then you can use the fuzzing book resources in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"notebooks/\") # add the notebooks directory to the path\n",
    "\n",
    "import bookutils\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from Fuzzer import RandomFuzzer\n",
    "from html.parser import HTMLParser\n",
    "from Coverage import Coverage\n",
    "import pickle\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Preparation**\n",
    "\n",
    "## Choose the target SUT & Initialize the fuzzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A program-under-test: HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_parser(inp: str) -> None:\n",
    "    parser = HTMLParser()\n",
    "    parser.feed(inp)\n",
    "\n",
    "# Getting the coverage given the input\n",
    "inp = \"<html>\"\n",
    "\n",
    "with Coverage() as cov:\n",
    "    my_parser(inp)\n",
    "cov.coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simple fuzzer: random string generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzer = RandomFuzzer(\n",
    "    min_length=1, max_length=100, char_start=32, char_range=94\n",
    ")\n",
    "print(\"input 1:\", fuzzer.fuzz())\n",
    "print(\"input 2:\", fuzzer.fuzz())\n",
    "print(\"input 3:\", fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ease of use: Coverage $\\rightarrow$ Hexstring (hashing) (:= a color of a ball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage -> hexstring (a colored ball)\n",
    "def getCovHash(cov: Coverage) -> str:\n",
    "    pickledCov = pickle.dumps(cov.coverage())\n",
    "    hashedCov = hashlib.md5(pickledCov).hexdigest()\n",
    "    return hashedCov\n",
    "\n",
    "covlist = list(cov.coverage())\n",
    "print(\n",
    "f\"The coverage [{covlist[0]}\\n\"\n",
    "f\"              {covlist[1]}\\n\"\n",
    "f\"              {covlist[2]}\\n\"\n",
    "f\"              {covlist[3]}\\n\"\n",
    "f\"              {covlist[4]}\\n\"\n",
    "f\"              ...]\")\n",
    "print(f\"is converted to the color {getCovHash(cov)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The rarity differs for different coverage (color)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First 10 samples (= coverage from execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n: number of samples\n",
    "n = 10\n",
    "print(f\"{n} samples from the urn:\")\n",
    "for i in range(n):\n",
    "    inp = fuzzer.fuzz()\n",
    "    with Coverage() as cov:\n",
    "        my_parser(inp)\n",
    "    print(f\"| sample {i + 1:2d}th: {getCovHash(cov)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of frequencies of colors (n = 10,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n: number of samples\n",
    "n = 10000\n",
    "\n",
    "# Population of inputs\n",
    "population = []\n",
    "for i in range(n):\n",
    "    population.append(fuzzer.fuzz())\n",
    "\n",
    "############# Record the frequency of each coverage #############\n",
    "# all_coverage_dict: coverage hash -> frequency\n",
    "#################################################################\n",
    "all_coverage_dict = {}\n",
    "for inp in population:\n",
    "    pass # IMPLEMENT HERE!\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "num_unique = len(all_coverage_dict)\n",
    "print(f\"Number of unique color: {num_unique}\")\n",
    "print(\n",
    "    f\"Top 3 frequencies: {sorted(list(all_coverage_dict.values()), reverse=True)[:3]}\"\n",
    ")\n",
    "print(f\"Bottom 3 frequencies: {sorted(list(all_coverage_dict.values()))[:3]}\")\n",
    "freqs = sorted(list(all_coverage_dict.values()), reverse=True)\n",
    "# print bar chart of the frequencies\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(range(len(freqs))), y=freqs, ax=ax)\n",
    "# remove the x labels\n",
    "ax.set_xticks([])\n",
    "# set log-scale for y-axis\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Definitions\n",
    "\n",
    "- Singletons: colors that appear only once in the sample\n",
    "- Doubletons: colors that appear twice in the sample\n",
    "\n",
    "$$\n",
    "\\Phi_k = \\text{the number of colors that appear $k$ times in the sample}\n",
    "$$\n",
    "\n",
    "- $\\Phi_1$ = the number of singletons, $\\Phi_2$ = the number of doubletons, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Number of Singletons & Doubletons #####\n",
    "singletons = -1 # IMPLEMENT HERE!\n",
    "doubletons = -1 # IMPLEMENT HERE!\n",
    "#############################################\n",
    "\n",
    "print(\n",
    "    \"The number of color seen exactly once is \"\n",
    "    + str(len(singletons))\n",
    ")\n",
    "print(\n",
    "    \"The number of color seen exactly twice is \"\n",
    "    + str(len(doubletons))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ðŸ’¡ Go back to the slides***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Missing Mass**: What is the probability that the next input will have a new coverage?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good-Turing estimator\n",
    "\n",
    "$$\n",
    "\\hat{M}_0^{\\text{GoodTuring}} = \\frac{\\Phi_1}{n},\n",
    "$$\n",
    "\n",
    "where $\\Phi_1$ is the number of singletons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Good-Turing ##############\n",
    "estimate = -1 # IMPLEMENT HERE!\n",
    "##########################################\n",
    "\n",
    "print(\n",
    "    f\"The probability that the next sample has a new color is estimated as {estimate}.\\n\"\n",
    "    f\"      (= the probability of observing a new coverage)\\n\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we evaluate this?\n",
    "\n",
    "### Evaluate the estimator empirically\n",
    "\n",
    "We run the fuzzer for additional number of iterations (e.g., n = 10,000) and check how many new coverages we actually get.\n",
    "Then, \n",
    "$$\n",
    "\\frac{\\text{new coverage}}{\\text{number of iterations}}\n",
    "$$\n",
    "is the empirical estimate of the missing mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Empirical Evaluation ###################\n",
    "# empirical: empirical probability of observing a new color from additional \n",
    "#            n samples of the validation set\n",
    "###########################################################\n",
    "validation = []\n",
    "for i in range(n):  # sample the same number of inputs as in the population\n",
    "    validation.append(fuzzer.fuzz())\n",
    "\n",
    "empirical = -1.0 # IMPLEMENT HERE!\n",
    "###########################################################\n",
    "\n",
    "print(\n",
    "    f\"The empirically probability that the next sample has a new color from {n} additional samples is {empirical}.\\n\"\n",
    ")\n",
    "print(f\"Good-Turing estimate : {estimate}\")\n",
    "print(f\"Empirical probability: {empirical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go up to n = 100,000 and compare the **Good-Turing estimator** with the **empirical missing mass**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 200000 # double of n, as we will use another half for validation\n",
    "samples = []\n",
    "for i in range(n):\n",
    "    inp = fuzzer.fuzz()\n",
    "    with Coverage() as cov:\n",
    "        try:\n",
    "            my_parser(inp)\n",
    "        except BaseException:\n",
    "            pass\n",
    "    cov_hash = getCovHash(cov)\n",
    "    samples.append(cov_hash)\n",
    "\n",
    "##################### Sampling and Estimation #####################\n",
    "# xs: list of sample sizes [x1, x2, ..., x100]\n",
    "# es: list of Good-Turing estimates when the sample size is xi\n",
    "# ps: list of empirical probabilities when the sample size is xi\n",
    "###################################################################\n",
    "xs = np.logspace(2, 5, 100)\n",
    "xs = [int(x) for x in xs]\n",
    "es = []\n",
    "ps = []\n",
    "for x in xs:\n",
    "    pass # IMPLEMENT HERE!\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(xs, es, label=\"Good-Turing estimate\")\n",
    "ax.plot(xs, ps, label=\"Emp-Prob(unseen)\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Number of samples (log-scale)\")\n",
    "ax.set_ylabel(\"Prob(unseen) (log-scale)\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ðŸ’¡ Go back to the slides :)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Species Richness**: What is the maximum coverage we can achieve?\n",
    "\n",
    "## Chao estimator\n",
    "\n",
    "The estimate of the lower bound of the remaining coverage is\n",
    "$$\n",
    "\\frac{n - 1}{n}\\frac{(\\Phi_1)^2}{2\\Phi_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000\n",
    "population = []\n",
    "for i in range(n):\n",
    "    population.append(fuzzer.fuzz())\n",
    "\n",
    "#################################################################\n",
    "# Get the number of singletons and doubletons after sampling\n",
    "# curr_coverage: a set of unique coverage hashes found from the population\n",
    "# num_singletons: the number of coverage hashes that are seen exactly once\n",
    "# num_doubletons: the number of coverage hashes that are seen exactly twice\n",
    "#################################################################\n",
    "curr_coverage = set()\n",
    "for inp in population:\n",
    "    pass # IMPLEMENT HERE!\n",
    "num_singletons = -1\n",
    "num_doubletons = -1\n",
    "#################################################################\n",
    "\n",
    "print(f\"[        Found] The number of unique colors found so far is {len(curr_coverage)}\")\n",
    "print(\n",
    "    \"[    Singleton] The number of color seen exactly once is \"\n",
    "    + str(num_singletons)\n",
    ")\n",
    "print(\n",
    "    \"[    Doubleton] The number of color seen exactly twice is \"\n",
    "    + str(num_doubletons)\n",
    ")\n",
    "\n",
    "############# Chao estimator #############\n",
    "estimate = -1  # IMPLEMENT HERE!\n",
    "##########################################\n",
    "\n",
    "print(\n",
    "    f\"[Chao Estimate] The lower bound of the number of coverages that are still unexplored is estimated by {estimate}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we evaluate this?\n",
    "\n",
    "### Again, evaluate the estimator empirically\n",
    "\n",
    "Let's try to run the fuzzer **much longer** and see if we can reach the Chao estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Empirical Evaluation ##########\n",
    "multiplier = 5\n",
    "extra_trials = n * multiplier\n",
    "validation = []\n",
    "for i in range(extra_trials):\n",
    "    validation.append(fuzzer.fuzz())\n",
    "\n",
    "extra_coverage = set()\n",
    "for idx, inp in enumerate(validation, 1):\n",
    "    pass  # IMPLEMENT HERE!\n",
    "    if idx % (n / 2) == 0:\n",
    "        num_new_coverage = -1\n",
    "        print(f\"After {idx} more samples, {num_new_coverage} new coverages are found.\")\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ðŸ’¡ Go back to the slides***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extrapolation**: How much can I discover more when I spend $X$ more time here?\n",
    "\n",
    "- $\\Delta(m)$: the number of new discoveries when $m$ more samples are retrieved.\n",
    "\n",
    "$$\n",
    "\\hat \\Delta(m) = \\hat \\Phi_0 \\left[1 - \\left(1 - \\frac{\\Phi_1}{n\\hat \\Phi_0 + \\Phi_1} \\right)^m\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I'm going to do:\n",
    "\n",
    "### 1. **Initial sample of size 200,000:** Check the coverage incrase & Count the number of **singletons** ($\\Phi_1$) and **doubletons** ($\\Phi_2$).\n",
    "### 2. **Extrapolation:** Estimate how the coverage discovery will increase for the **next 200,000 samples** with the estimator above.\n",
    "### 3. **Comparison with the empirical result:** Actually getting 200,000 samples more and see how the coverage discovery empirically increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 200,000 inputs => Initial sample data\n",
    "n = 200000\n",
    "population = []\n",
    "for i in range(n):\n",
    "    population.append(fuzzer.fuzz())\n",
    "\n",
    "############################################################\n",
    "# cumulative_coverage: list of cumulative number of unique coverages (len = n)\n",
    "# num_singletons: the number singletons in the first 200,000 inputs\n",
    "# num_doubletons: the number doubletons in the first 200,000 inputs\n",
    "# num_singletons and num_doubletons are used for extrapolation\n",
    "############################################################\n",
    "cumulative_coverage = []\n",
    "# IMPLEMENT HERE!\n",
    "num_singletons = -1\n",
    "num_doubletons = -1\n",
    "\n",
    "############################################################\n",
    "# Additional 200,000 inputs => Validation data (not used for extrapolation)\n",
    "# Append the cumulative number of unique coverages found from the validation \n",
    "# data to cumulative_coverage (len: n -> n + extra_n)\n",
    "############################################################\n",
    "extra_n = 200000\n",
    "validation = []\n",
    "for i in range(extra_n):\n",
    "    validation.append(fuzzer.fuzz())\n",
    "\n",
    "for inp in validation:\n",
    "    pass # IMPLEMENT HERE!\n",
    "    cumulative_coverage.append(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) How the coverage increases with the first 200,000 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "coverage_ateach_1000trial = [0] + cumulative_coverage[\n",
    "    999::1000\n",
    "]  # for every 1000 trials\n",
    " # the first half of cumulative_coverage (until n = 100,000)\n",
    "sub_coverage_until_half = coverage_ateach_1000trial[:201]\n",
    "sns.lineplot(\n",
    "    x=range(0, n + 1, 1000),\n",
    "    y=sub_coverage_until_half,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlim(0, 2 * n)\n",
    "ax.set_ylim(0, cumulative_coverage[-1])\n",
    "ax.set_xticks([0, n / 2, n, n * 3 / 2, 2 * n])\n",
    "ax.set_xlabel(\"Number of inputs\")\n",
    "ax.set_ylabel(\"Number of unique coverages\")\n",
    "ax.set_title(\"Coverage growth over time (200,000 inputs)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) Extrapolation of the coverage increase for the next 200,000 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Extrapolation ##############################\n",
    "# extrapolated: list of extrapolated number of unique coverages after n inputs\n",
    "# (len: n)      and up to 2n inputs; will be compared with the validation data,\n",
    "#               i.e., the second half of cumulative_coverage\n",
    "########################################################################\n",
    "extrapolated = [] # IMPLEMENT HERE!\n",
    "########################################################################\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    x=range(0, n + 1, 1000),\n",
    "    y=sub_coverage_until_half,\n",
    "    ax=ax,\n",
    "    color=\"black\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=range(n + 1000, n * 2 + 1, 1000),\n",
    "    y=extrapolated[999::1000],\n",
    "    ax=ax,\n",
    "    color=\"blue\",\n",
    "    dashes=True,\n",
    ")\n",
    "ax.set_xlabel(\"Number of inputs\")\n",
    "ax.set_ylabel(\"Number of unique coverages\")\n",
    "ax.set_title(\"Coverage growth over time (blue: extrapolated)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Comparison: Extrapolate vs. How the coverage increases empirically with the next 200,000 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    x=range(0, n + 1, 1000),\n",
    "    y=sub_coverage_until_half,\n",
    "    ax=ax,\n",
    "    color=\"black\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=range(n + 1000, n * 2 + 1, 1000),\n",
    "    y=extrapolated[999::1000],\n",
    "    ax=ax,\n",
    "    color=\"blue\",\n",
    "    dashes=True,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=range(n + 1000, n * 2 + 1, 1000),\n",
    "    y=coverage_ateach_1000trial[201:],\n",
    "    ax=ax,\n",
    "    color=\"red\",\n",
    ")\n",
    "ax.set_xlabel(\"Number of inputs\")\n",
    "ax.set_ylabel(\"Number of unique coverages\")\n",
    "ax.set_title(\"Coverage growth over time (blue: extrapolated, red: validation)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ðŸ’¡ Go back to the slides***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
